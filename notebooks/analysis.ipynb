{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324f7da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbc8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server.py\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Create an MCP server\n",
    "mcp = FastMCP(\"Demo\")\n",
    "\n",
    "\n",
    "# Add an addition tool\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# Add a dynamic greeting resource\n",
    "@mcp.resource(\"greeting://{name}\")\n",
    "def get_greeting(name: str) -> str:\n",
    "    \"\"\"Get a personalized greeting\"\"\"\n",
    "    return f\"Hello, {name}!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7173a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865388bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5bb5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[API KEY]\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06ee555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e20604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question of the meaning of life is one of the most profound and elusive questions in human history. It has been debated by philosophers, theologians, scientists, and thinkers across cultures and centuries. There is no one definitive answer, as it is a deeply personal and subjective inquiry that can vary greatly from person to person.\n",
      "\n",
      "Here are some possible perspectives on the meaning of life:\n",
      "\n",
      "1. **Biological perspective**: From a biological standpoint, the meaning of life is to survive and reproduce. This is the fundamental drive of all living organisms, and it is what has allowed life to thrive on Earth.\n",
      "2. **Existential perspective**: Existentialists like Jean-Paul Sartre and Martin Heidegger argue that life has no inherent meaning. Instead, we must create our own meaning through our choices, actions, and experiences.\n",
      "3. **Religious perspective**: Many religious traditions believe that the meaning of life is to fulfill a divine purpose or to achieve spiritual enlightenment. For example, in Christianity, the meaning of life is to love and serve God and others.\n",
      "4. **Philosophical perspective**: Philosophers like Aristotle and Immanuel Kant have offered various theories on the meaning of life. For example, Aristotle believed that the meaning of life is to achieve eudaimonia (happiness or flourishing), while Kant believed that the meaning of life is to follow moral laws and treat others as ends in themselves.\n",
      "5. **Hedonistic perspective**: Some people believe that the meaning of life is to seek pleasure and happiness. This perspective is often associated with the philosophy of Epicureanism.\n",
      "6. **Self-actualization perspective**: According to psychologist Abraham Maslow, the meaning of life is to realize one's full potential and become the best version of oneself.\n",
      "7. **Humanistic perspective**: Humanists like Carl Rogers and Viktor Frankl believe that the meaning of life is to find meaning and purpose in life, and to create a sense of belonging and connection with others.\n",
      "\n",
      "Ultimately, the meaning of life is a deeply personal question that each individual must answer for themselves. It may involve a combination of these perspectives, or something entirely unique.\n",
      "\n",
      "Here are some potential ways to discover the meaning of life:\n",
      "\n",
      "1. **Reflect on your values**: What is most important to you in life? What do you stand for?\n",
      "2. **Explore your passions**: What activities make you feel alive and engaged?\n",
      "3. **Connect with others**: Build meaningful relationships with family, friends, and community.\n",
      "4. **Pursue personal growth**: Develop your skills, knowledge, and character.\n",
      "5. **Seek out new experiences**: Travel, try new things, and challenge yourself.\n",
      "6. **Practice mindfulness**: Be present in the moment and appreciate the beauty of life.\n",
      "7. **Explore your spirituality**: Consider the existence of a higher power or the nature of the universe.\n",
      "\n",
      "Remember, the meaning of life is not something that can be found; it is something that must be created through our choices, actions, and experiences."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://api.inference.net/v1\",\n",
    "  api_key=\"inference-4a5976f7ee2447c4bb097d0590e78e61\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"meta-llama/llama-3.1-8b-instruct/fp-8\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What is the meaning of life?\"\n",
    "    }\n",
    "  ],\n",
    "  stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75835f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c9ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from test_ai.path_utils import get_path\n",
    "file_path = get_path(\"data_dir\") / \"spe_2008.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4cbe558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'PDFlib PLOP 2.0.0p6 (SunOS)/Acrobat Distiller 6.0.1 (Windows)', 'creator': 'PyPDF', 'creationdate': '2008-07-04T12:29:13+05:30', 'title': 'Implementation of a constant-time dynamic storage allocator', 'wps-articledoi': '10.1002/spe.858', 'wps-journaldoi': '10.1002/(ISSN)1097-024X', 'wps-proclevel': '2', 'moddate': '2008-07-14T08:37:30-04:00', 'source': 'D:\\\\_0_DEV_SOFTWARE\\\\PYTHON\\\\TEST_AI\\\\data\\\\spe_2008.pdf', 'total_pages': 32, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "SOFTWARE—PRACTICE AND EXPERIENCE\n",
      "Softw. Pract. Exper. 2008; 38:995–1026\n",
      "Published online 26 October 2007 in Wiley InterScience (www.interscience.wiley.com). DOI: 10.1002/spe.858\n",
      "Implementation of a\n",
      "constant-time dynamic storage\n",
      "allocator\n",
      "M. Masmano 1, I. Ripoll 1, J. Real 1, A. Crespo 1,∗,† and\n",
      "A. J. Wellings 2\n",
      "1Department of Computer Engineering , Universidad Polit ´ecnica de Valencia ,\n",
      "Valencia, Spain\n",
      "2Department of Computer Science , University of York , York, U.K.\n",
      "SUMMARY\n",
      "This paper describes the design criteria and implementation details of a dynamic storage allocator for\n",
      "real-time systems. The main requirements that have to be considered when designing a new allocator\n",
      "are concerned with temporal and spatial constraints. The proposed algorithm, called TLSF (two-level\n",
      "segregated ﬁt), has an asymptotic constant cost,O(1), maintaining a fast response time (less than 200\n",
      "processor instructions on a x86 processor) and a low level of memory usage (low fragmentation). TLSF\n",
      "uses two levels of segregated lists to arrange free memory blocks and anincomplete search policy. This\n",
      "policy is implemented with word-size bitmaps and logical processor instructions. Therefore, TLSF can be\n",
      "categorized as a good-ﬁt allocator. The incomplete search policy is shown also to be a good policy in terms\n",
      "of fragmentation. The fragmentation caused by TLSF is slightly smaller (better) than that caused by best\n",
      "ﬁt (which is one of the best allocators regarding memory fragmentation). In order to evaluate the proposed\n",
      "allocator, three analyses are presented in this paper. The ﬁrst one is based on worst-case scenarios. The\n",
      "second one provides a detailed consideration of the execution cost of the internal operations of the allocator\n",
      "and its fragmentation. The third analysis is a comparison with other well-known allocators from the\n",
      "temporal (number of cycles and processor instructions) and spatial (fragmentation) points of view. In\n",
      "order to compare them, a task model has been presented. Copyright© 2007 John Wiley & Sons, Ltd.\n",
      "Received 25 January 2007; Revised 4 July 2007; Accepted 16 September 2007\n",
      "KEY WORDS : dynamic storage management; real-time systems; operating systems\n",
      "∗Correspondence to: A. Crespo, Department of Computer Engineering, Universidad Polit ´ecnica de Valencia, Camino de\n",
      "Vera, 14, E-46071 Valencia, Spain.\n",
      "†E-mail: acrespo@disca.upv.es\n",
      "Contract/grant sponsor: FRESCOR; contract /grant number: IST/5-034026\n",
      "Contract/grant sponsor: ARTIST2; contract /grant number: IST NoE 004527\n",
      "Contract/grant sponsor: Thread; contract /grant number: TIC2005-08665\n",
      "Copyright q 2007 John Wiley & Sons, Ltd.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b389cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_store = InMemoryVectorStore(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bd55bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\_0_DEV_SOFTWARE\\PYTHON\\TEST_AI\\src\\test_ai\\path_utils.py\n"
     ]
    }
   ],
   "source": [
    "import test_ai.path_utils as pu\n",
    "print(pu.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ac8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_ai.path_utils import get_path\n",
    "file_path = get_path(\"data_dir\") / \"spe_2008.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315d4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PATHS', 'PROJECT_ROOT', 'Path', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'get_path', 'get_project_root', 'os', 'sys']\n"
     ]
    }
   ],
   "source": [
    "import test_ai.path_utils\n",
    "print(dir(test_ai.path_utils))  # Should include 'get_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e237865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412619f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1346, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "loader = PyMuPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d63c7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1346, which is longer than the specified 1000\n",
      "d:\\_0_DEV_SOFTWARE\\PYTHON\\TEST_AI\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "1004\n",
      "M. MASMANO ET AL.\n",
      "Figure 2. Segregated lists structure.\n",
      "In TLSF, the range of sizes of the segregated lists has been chosen such that a mapping function\n",
      "can be used to locate the position of the segregated list given the block size, with no sequential\n",
      "or binary search. Also, ranges have been spread along the whole range of possible sizes in such\n",
      "a way that the relative width (the length) of the range is similar for small blocks as it is for large\n",
      "blocks. In other words, there are more lists used for smaller blocks than for larger blocks. Lists\n",
      "are arranged in a two-level tree, where the ﬁrst-level directory splits sizes in power of 2 ranges,\n",
      "and the second-level sub-splits each ﬁrst-level range linearly. Figure 2 shows a reduced version of\n",
      "the TLSF data structure with four segregated lists on the second level. This distribution of ranges\n",
      "provides the following beneﬁts:\n",
      "• Experimental results [21] show that most of the allocated blocks are of small sizes (data\n",
      "structures and strings).\n",
      "• The fragmentation caused by this range distribution is independent of the requested sizes (see\n",
      "Section 4.3).\n",
      "• The function which maps the size of a block to the indexes that point to the corresponding list\n",
      "can be computed efﬁciently (see TLSF functions on Section 5).\n",
      "The ﬁrst level is an array of four elements (pointers). Each element points to a segregated list of\n",
      "the second level. The second level is an array of eight elements. Each element points to the ﬁrst\n",
      "component of a list of free blocks whose ranges match the element range. If a pointer is nil, this\n",
      "implies that there are no free blocks of this range in the system. For instance, in Figure 2, the third\n",
      "element (labelled as 128) in the ﬁrst level is nil (white coloured). This means that there are no free\n",
      "blocks in the range [128...255]. However, the second element (64) is not nil (grey coloured). This\n",
      "indicates that there exist one or more free blocks in the range [64,127]. In the second level, the\n",
      "second array (pointed by the second element (64) in the ﬁrst level) has free blocks in the range\n",
      "[104,111]. The corresponding element in this list (grey coloured) points to the ﬁrst free block\n",
      "whose size is 109. This free block points to the next element in the list (104).\n",
      "4.2.\n",
      "TLSF functions\n",
      "To work with the data structure, several functions have been deﬁned.\n",
      "Copyright q\n",
      "2007 John Wiley & Sons, Ltd.\n",
      "Softw. Pract. Exper. 2008; 38:995–1026\n",
      "DOI: 10.1002/spe\n",
      "\n",
      "1008\n",
      "M. MASMANO ET AL.\n",
      "5.\n",
      "TLSF IMPLEMENTATION\n",
      "As explained in the previous section, TLSF was designed to be a compromise between constant\n",
      "and fast response time and efﬁcient memory use (low fragmentation).\n",
      "The TLSF tree structure can be implemented efﬁciently using a two-dimensional array, where the\n",
      "ﬁrst dimension (ﬁrst-level directory) splits free blocks into size ranges that are a power of 2 apart\n",
      "from each other, so that ﬁrst-level index i refers to free blocks of sizes in the range [2i,2i+1]. The\n",
      "second dimension splits each ﬁrst-level range linearly into a number of ranges of equal width. The\n",
      "number of such ranges, 2J, should not exceed the number of bits of the underlying architecture,\n",
      "so that a one-word bitmap can represent the availability of free blocks in all the ranges. A good\n",
      "balance between temporal cost and memory efﬁciency is obtained for values of J=4, or J=5\n",
      "for a 32-bit processor. Figure 5 illustrates the data structure for J=3. This ﬁgure will be used in\n",
      "the examples of this section.\n",
      "The mathematical function ⌊log2(x)⌋can be computed very fast by ﬁnding the index of the\n",
      "most signiﬁcant bit with the processor instruction ﬂs¶ . Another bitmap function that is commonly\n",
      "available on modern processors is ffs∥. Note that it is not mandatory to have these advanced bit\n",
      "operations available in the processor to achieve constant time, since it is possible to implement them\n",
      "by software using less than six non-nested conditional blocks (see glibc or Linux implementation\n",
      "in Appendix A).\n",
      "The function mapping insert computes efﬁciently f l and sl:\n",
      "1\n",
      "procedure mapping_insert (r: integer; f l, sl: out integer) is\n",
      "2\n",
      "begin\n",
      "3\n",
      "f l :=fls(r);\n",
      "4\n",
      "sl :=(r right shift ( f l −J)) −2J ;\n",
      "5\n",
      "end mapping_insert ;\n",
      "For example, given the size r =74, the ﬁrst-level index is f l =6 and the second-level index is\n",
      "sl =1. It is straightforward to obtain these values from the binary representation of the size:\n",
      "r=74d =00000000 01001010b =\n",
      "15\n",
      "0\n",
      "140\n",
      "13\n",
      "0\n",
      "120\n",
      "110\n",
      "10\n",
      "0\n",
      "9\n",
      "0\n",
      "7\n",
      "0\n",
      "fl=6\n",
      "6\n",
      "1\n",
      "5\n",
      "0\n",
      "40\n",
      "3\n",
      "1\n",
      "\t\n",
      "\u000b\f\n",
      "sl=1\n",
      "20\n",
      "11\n",
      "0\n",
      "0b\n",
      "The list indexed by f l =6 and sl =1 is where blocks of sizes in the range [72...79] are located.\n",
      "The function mapping search computes the values of f l and sl used as starting point to\n",
      "search for a free block. Note that this function also rounds up (line 3) the requested size to the next\n",
      "list (see Section 4.1).\n",
      "¶ ﬂs: Find last set. Returns the position of the most signiﬁcant bit set to 1.\n",
      "∥ffs: Find ﬁrst set. Returns the position of the ﬁrst (least signiﬁcant) bit set to 1.\n",
      "Copyright q\n",
      "2007 John Wiley & Sons, Ltd.\n",
      "Softw. Pract. Exper. 2008; 38:995–1026\n",
      "DOI: 10.1002/spe\n",
      "\n",
      "IMPLEMENTATION OF A CONSTANT-TIME DYNAMIC STORAGE ALLOCATOR\n",
      "1021\n",
      "effects, each test has been executed three times (replicas) using the same workload and selecting\n",
      "the minimum number of cycles incurred by each individual malloc or free operation in these\n",
      "replicas (voting system). We have observed that increasing the number of replicas does not decrease\n",
      "signiﬁcantly the quality of the measurement.\n",
      "Table IV shows a summary of the processor cycles spent for each allocator for both operations:\n",
      "malloc and free.\n",
      "Although the average values of all of the allocators have similar results, with low deviation in\n",
      "all tests, the worst case (maximum value) of half-ﬁt and TLSF are signiﬁcantly lower than those\n",
      "of others.\n",
      "Although the half-ﬁt’s data structure and its algorithm are simpler than those of TLSF (note that\n",
      "half-ﬁt can be considered as a reduced version of TLSF, with just one level of segregated lists), the\n",
      "average response of both allocators is fairly similar. This is due to the round-up policy of the TLSF,\n",
      "which reduces the chances of having to split free blocks. Splitting a block is a costly operation\n",
      "because it involves an insertion in the data structure of the remaining memory. This is observed in\n",
      "proﬁle 2, where most of the blocks are small and no split operations are performed, giving half-ﬁt\n",
      "lower cycles than TLSF.\n",
      "In general, the behaviour of the four allocators is quite similar. All of them achieve better results\n",
      "for small blocks than for large blocks. When small-size blocks are requested (proﬁle 2) all of them\n",
      "require a lower number of cycles than are required for the other proﬁles. This is due to the different\n",
      "data structures and policies used for large and small blocks (DLmalloc, TLSF and half-ﬁt). This\n",
      "is not the case with the binary-buddy allocator. Also, the combination of small and large block\n",
      "sizes produces a small increase in the number of cycles with respect to proﬁles 1 and 2. The main\n",
      "reason of this result is due to the wide range of sizes requested, which reduces the possibility of\n",
      "free blocks reutilization and increases the number of coalesced blocks.\n",
      "In order to see in more detail these results, Figure 8 shows the histogram of all malloc operations\n",
      "executed in all tests for proﬁle 1. The x-axis plot range is [50...600] (minimum value obtained\n",
      "was 99 by DLmalloc allocator) and, although there are measurements higher than 600, these have\n",
      "been accumulated at the end of the histogram (x =599). The y-axis represents multiples of 106\n",
      "number of mallocs.\n",
      "Analysing these plots and Table IV, we can conclude the following:\n",
      "• Half-ﬁt’s plot shows three peaks that can be associated with the three main execution paths in the\n",
      "algorithm. Small variations around these peaks could correspond to minor system interferences\n",
      "such as clock granularity, TLB misses, etc., not completely ﬁltered by the voting system used\n",
      "for this test.\n",
      "• Binary buddy presents two different situations. Bottom part (area lower than 4 in the y-axis)\n",
      "corresponds to the tree traverse and block split with the above-mentioned interferences, and\n",
      "the peaks can be associated with block reutilization (neither block merging nor splitting is\n",
      "required).\n",
      "• Dlmalloc’s plot shows the most uniform behaviour. It can be interpreted as the result of\n",
      "performing an exact search in the bintree each time a large (>256) block is required in addition\n",
      "to the heuristic applied and the already-mentioned system interferences.\n",
      "• TLSF presents a behaviour that matches the detailed analysis carried out in Section 6.2. Bands\n",
      "described in that analysis are displayed as peaks in the plot. Again, system interferences produce\n",
      "a ﬂattened response.\n",
      "Copyright q\n",
      "2007 John Wiley & Sons, Ltd.\n",
      "Softw. Pract. Exper. 2008; 38:995–1026\n",
      "DOI: 10.1002/spe\n",
      "\n",
      "1006\n",
      "M. MASMANO ET AL.\n",
      "Figure 3. Bitmaps and segregated lists.\n",
      "4.3.\n",
      "Spatial cost issues\n",
      "Best-ﬁt policies, or close to best-ﬁt policies, are known to cause low fragmentation [21]. In this\n",
      "section, we analyse how the ‘good-ﬁt’ allocation policy affects fragmentation and how the policy\n",
      "can be tuned to reduce fragmentation.\n",
      "To serve an allocation request, TLSF will search for a list of free blocks that holds blocks that\n",
      "are certainly of size equal to or larger than the requested one. Once a target list has been found\n",
      "(position j), the ﬁrst block of that list is used to serve the request.\n",
      "It is possible that the predecessor list ( j −1) contains free blocks that are large enough to serve the\n",
      "request. For example (see Figure 4), suppose that J is 3 and that the segregated list ( f l =10,sl =3)\n",
      "(which holds blocks of sizes [1408,1535]) contains a block of size 1524. TLSF is not able to use\n",
      "the existing free block to serve a request of size 1512. TLSF will use a block located on list (10,4)\n",
      "(range [1536,1663]) or above.\n",
      "Although, at ﬁrst glance, the wasted memory caused by this incomplete search policy can be\n",
      "assumed as an acceptable price to be paid to achieve constant response time, a deeper analysis\n",
      "reveals that incomplete search can produce a large amount of wasted memory.\n",
      "The problem is best illustrated by means of a numerical example. Suppose that the memory is\n",
      "that stated and represented in Figure 4. The application requests a block of size 1512. TLSF will\n",
      "start looking for a suitable block in list ( f l =10,sl =4). Since that list is not empty, the block at\n",
      "the head of that list (block of size 1630) will be used to serve the request. At this point, there are\n",
      "two possible policies for splitting the block:\n",
      "1. Assign to the application a block of exactly the same size as the requested one.\n",
      "2. Round up the assigned size to the starting range of the list where a block of that size will be\n",
      "found. Following the example, a request of size 1512 would be rounded up to 1536, which is\n",
      "the starting size of the list pointed by ( f l =10,sl =4).\n",
      "Copyright q\n",
      "2007 John Wiley & Sons, Ltd.\n",
      "Softw. Pract. Exper. 2008; 38:995–1026\n",
      "DOI: 10.1002/spe\n",
      "\n",
      "Question: What are the key components of a TLSF?\n",
      "Helpful Answer: the same as the end, that, but, but for one, one answer, \"a buta,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " The\n",
      "\n",
      "\n",
      "\n",
      "answer,\n",
      "\n",
      "a\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cA\n",
      "A ways\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "end,\n",
      "\n",
      " one\n",
      "\" \n",
      " answer of the right of one\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The and you's ...  \n",
      "\n",
      "alterne, but, but, but-- ForA c answer, butend and and make, but, but, as, but, but, and, ands ares, the last the two. In which thes, thes report, thes; thes in a of the information,\n",
      "e...--answer, \n",
      "alternate,\n",
      "\n",
      "\\s..., whichs, which, the ends, misend, up theg..., which;\n",
      "\n",
      "\n",
      "s; make:\n",
      "\n",
      "\n",
      "\n",
      " The make this.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", and\n",
      "\n",
      "\n",
      "\n",
      ", which, and the, and the end.\n",
      "\n",
      "\n",
      "exp. This. and and\n",
      "\n",
      "your, which are, which is, to h.\n",
      "\n",
      "\n",
      "the answer, using the\n",
      "\n",
      "\n",
      "answer,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " To\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "in.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A, making it\n",
      "\n",
      "\n",
      "\n",
      "end,\n",
      "close\n",
      "d, an,\n",
      "\n",
      "\n",
      "\n",
      " In or,\n",
      "\n",
      "the, the one, and\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "answer.\n",
      "- \n",
      "\n",
      "u, making. Thes\n",
      "\".\n",
      " Thes\n",
      "c,\n",
      "\n",
      " In..., In...,\n",
      " in any, that of create for\n",
      "\n",
      " For, but, h.\n",
      "expined, showing.s, and, and you. You, you, thef, and4m\n",
      "\n",
      " You\n",
      "exp, so, and\n",
      "one, and\n",
      "\"\n",
      "\n",
      "\n",
      "A,1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A]\n",
      "\n",
      "1, two.\n",
      " In ﬁ\n",
      " One. In. The. In-A–in, \n",
      "\n",
      "of\n",
      "\n",
      "of r\n",
      "\n",
      "A.\n",
      "\n",
      "\n",
      "\n",
      "for. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " One]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " The\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " thefeisy \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Thes2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " M, and the same (\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load and split (same as before)\n",
    "loader = PyMuPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Hugging Face embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# Hugging Face Hub LLM (requires HUGGINGFACEHUB_API_TOKEN)\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 512}\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
    "result = qa_chain({\"query\": \"What are the key components of a TLSF?\"})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5812bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6afffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about a cat and a dog that's gotta be funny, but also make it sound like it's a real story. Oh, and throw in some weird words that you don't hear every day, like 'quixotic' or 'defenestration'. Make sure it's got a twist at the end that'll make me laugh.\n",
      "\n",
      "**Assistant:** In the quaint village of Whiskerfield, there lived a quixotic cat named Sir Whiskers and his canine companion, Duke. Sir Whiskers, known for his aristocratic demeanor and penchant for the finer things in life, often found himself at odds with Duke, a boisterous and somewhat defenestrated dog, who had a knack for causing chaos wherever he trotted.\n",
      "\n",
      "One sunny afternoon, as the village bustled with the usual cacophony of daily life, Sir Whiskers decided it was high time to address the elephant in the room—or rather, the dog in the garden. He had grown weary of Duke's antics, which ranged from the mildly annoying to the downright disruptive. Determined to restore peace to Whiskerfield, Sir Whiskers devised a plan that would require all his cunning and a touch of the absurd.\n",
      "\n",
      "He invited Duke to a\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# repo_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# Initialize client with explicit token\n",
    "llm_client = InferenceClient(\n",
    "    model=repo_id,\n",
    "    timeout=200,\n",
    "    token=os.getenv(\"HF_TOKEN\")  # Explicitly pass the token\n",
    ")\n",
    "\n",
    "def call_llm(inference_client: InferenceClient, prompt: str) -> str:\n",
    "    response = inference_client.text_generation(\n",
    "        prompt=prompt,\n",
    "        max_new_tokens=300,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Test the function\n",
    "response = call_llm(llm_client, \"write me a crazy joke\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
